{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize #package for flattening json in pandas df\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "with open('C:\\\\Users\\\\chq-shal\\\\Downloads\\\\projects_python\\\\project_workboard\\\\small3.json',encoding='utf-8') as d:\n",
    "    f=json.load(d)\n",
    "data=json_normalize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin=pd.to_datetime(data.beginTime, utc=True)\n",
    "end=pd.to_datetime(data.endTime, utc=True)\n",
    "compliant=end-begin<np.timedelta64(2,'h') # true is compliant, false is not compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload=data['payload'].apply(lambda row:pd.Series(json.loads(row))) # convert payload dictionaries to columns\n",
    "visibility=data['visibility'].apply(lambda row:pd.Series(json.loads(row))) # convert visibility dictionaries to columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting features to be added: pcsAct, wgtAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pcsAct        9564\n",
       "wgtAct        7286\n",
       "wgtDeclAct    7951\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(payload)\n",
    "# payload.count()\n",
    "# payload.typeOfGoods.value_counts()\n",
    "payload[['pcsAct', 'wgtAct', 'wgtDeclAct']].count() # wgtDeclAct is the same as wgtAct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows do not have any milestone codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(visibility)\n",
    "# visibility.count()\n",
    "# milestone=visibility[['dsn','els','frd','phd','sir','cdp','cpu','dra','drr','sli','osd','puo','lkp','smp','ecs','evr','ntc','cln','afs','sfs','ecc','cek','hot','aue','frf','ega','rud','ddn']]\n",
    "# milestone.count()\n",
    "# len(milestone)-len(milestone.dropna(how='all')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([begin,payload,visibility],axis=1)\n",
    "df=df.dropna(axis=1) # drop columns that have na values in them\n",
    "df=df.drop(['events','firstAware','etmsBranch','workBranch'],axis=1) # drop dict events, firstAware; drop dup etms, work\n",
    "df=df.loc[:,~df.columns.duplicated()] # drop dup columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create additional features from dateCreate and beginTime, run this before the next code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['dateDT']=pd.to_datetime(df.dateCreate, utc=True)\n",
    "df['diffS']=(df.dateDT-df.beginTime).dt.total_seconds()\n",
    "df['beginY']=df.beginTime.dt.dayofyear\n",
    "df['beginW']=df.beginTime.dt.dayofweek\n",
    "df['beginH']=df.beginTime.dt.hour\n",
    "df['dateY']=df.dateDT.dt.dayofyear\n",
    "df['dateW']=df.dateDT.dt.dayofweek\n",
    "df['dateH']=df.dateDT.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "too_sim=0.0003*len(df) # very similar values in a column\n",
    "too_dif=0.5*len(df) # very different values in a column\n",
    "for col in df.columns: # remove columns that have values that are too similar or too different\n",
    "    if df[col].nunique()<too_sim or df[col].nunique()>too_dif:\n",
    "        df.drop(col,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add interesting features back: pcsAct, wgtAct back. Drop rows where there is no wgtAct back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['pcsAct', 'wgtAct']]=payload[['pcsAct', 'wgtAct']]\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chq-shal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\chq-shal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\chq-shal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "compliance=compliant[pd.notnull(payload['wgtAct'])]\n",
    "X_train,X_test,y_train,y_test=train_test_split(pd.get_dummies(df),compliance,random_state=0)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999751737835153"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# clf=GradientBoostingClassifier(max_depth=2,random_state=0)\n",
    "# grid_values = {'learning_rate': [0.001, 0.01, 0.05, 0.1, 1, 10]}\n",
    "# grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "# grid_clf_auc.fit(X_train_scaled, y_train)\n",
    "# y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test_scaled)\n",
    "# print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "# print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "# print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "clf=GradientBoostingClassifier(learning_rate=1,max_depth=2,random_state=0) # build bradient boost model with learning rate=1\n",
    "gb_clf=clf.fit(X_train_scaled, y_train)\n",
    "gb_y_score=gb_clf.decision_function(X_test_scaled)\n",
    "gb_fpr, gb_tpr, _ = roc_curve(y_test, gb_y_score)\n",
    "gb_roc_auc = auc(gb_fpr, gb_tpr)\n",
    "gb_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mode              0.289424\n",
       "branch_HKG        0.100853\n",
       "diffS             0.083802\n",
       "beginY            0.057749\n",
       "portOrigin_SFO    0.051174\n",
       "dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=gb_clf.feature_importances_\n",
    "pd.Series(data=feature,index=list(X_train)).nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9491018751095274"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier()\n",
    "# grid_values = {'n_estimators': [200, 700],'max_features': ['auto', 'sqrt', 'log2']}\n",
    "# grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "# grid_clf_auc.fit(X_train_scaled, y_train)\n",
    "# y_decision_fn_scores_auc = grid_clf_auc.predict_proba(X_test_scaled)[:,1]\n",
    "# print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "# print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "# print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "clf=RandomForestClassifier(max_features='log2', n_estimators=700)\n",
    "rf_clf=clf.fit(X_train_scaled, y_train)\n",
    "rf_y_score=rf_clf.predict_proba(X_test_scaled)[:,1]\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_y_score)\n",
    "rf_roc_auc = auc(rf_fpr, rf_tpr)\n",
    "rf_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wgtAct    0.103063\n",
       "diffS     0.094701\n",
       "beginH    0.077398\n",
       "dateH     0.071397\n",
       "beginY    0.049330\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=rf_clf.feature_importances_\n",
    "pd.Series(data=feature,index=list(X_train)).nlargest(5) # mode is similar to shipment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8938817980022198"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# clf = KNeighborsClassifier(n_jobs=-1)\n",
    "# grid_values = {'n_neighbors': list(range(1,11))}\n",
    "# grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "# grid_clf_auc.fit(X_train_scaled, y_train)\n",
    "# y_decision_fn_scores_auc = grid_clf_auc.predict_proba(X_test_scaled)[:,1]\n",
    "# print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "# print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "# print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "clf=KNeighborsClassifier(n_neighbors=7,n_jobs=-1) # build knn model with neighbors=7\n",
    "knn_clf=clf.fit(X_train_scaled, y_train)\n",
    "knn_y_score=knn_clf.predict_proba(X_test_scaled)[:,1]\n",
    "knn_fpr, knn_tpr, _ = roc_curve(y_test, knn_y_score)\n",
    "knn_roc_auc = auc(knn_fpr, knn_tpr)\n",
    "knn_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chq-shal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\chq-shal\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1300: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8540320696302356"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# clf = LogisticRegression(n_jobs=-1)\n",
    "# grid_values = {'C': [1,10,100,1000]}\n",
    "# grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "# grid_clf_auc.fit(X_train_scaled, y_train)\n",
    "# y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test_scaled)\n",
    "# print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "# print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "# print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "clf=LogisticRegression(C=1,n_jobs=-1) # build logistic regression model with C=1\n",
    "lr_clf=clf.fit(X_train_scaled, y_train)\n",
    "lr_y_score=lr_clf.predict_proba(X_test_scaled)[:,1]\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_y_score)\n",
    "lr_roc_auc = auc(lr_fpr, lr_tpr)\n",
    "lr_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8286932647935041"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "dt_clf=clf.fit(X_train_scaled, y_train)\n",
    "dt_y_score=dt_clf.predict_proba(X_test_scaled)[:,1]\n",
    "dt_fpr, dt_tpr, _ = roc_curve(y_test, dt_y_score)\n",
    "dt_roc_auc = auc(dt_fpr, dt_tpr)\n",
    "dt_roc_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
